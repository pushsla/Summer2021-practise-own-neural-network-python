{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Реализация простой нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Нейрон\n",
    "Нейрон представляет собой следующий математический объект:\n",
    "\n",
    "$$n = f(\\vec w*\\vec x + h)$$\n",
    "\n",
    "Где *n* - результат работы нейрона, $\\vec x$ - значения, получаемые\n",
    "нейроном в качестве параметров, $\\vec w$ - корректировочные веса,\n",
    "придаваемые входным значениям, $h$ - свободный член, а $f(t)$ - функция активации\n",
    "\n",
    "Задача функции активации состоит в том, чтобы вычисляемые нейронами значения были\n",
    "ограничены, а также, как правило, в подавлении больших и \"усилении\" малых значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7129931052444277\n"
     ]
    }
   ],
   "source": [
    "# Попробуем реализовать свой собственный нейрон\n",
    "# В качестве функции активации выберем сигмоиду\n",
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "sig = lambda x: (ex := exp(x))/(ex + 1)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, inputs: int):\n",
    "        self.shape = (inputs,)\n",
    "        # Это веса нашего нейрона и свободный член\n",
    "        self.weights = np.random.rand(inputs + 1)\n",
    "\n",
    "    def calculate(self, x: np.array) -> np.array:\n",
    "        # проверим возможность матричного перемножения\n",
    "        if x.shape != self.shape:\n",
    "            raise Exception()\n",
    "        return sig(np.dot(self.weights, np.append(x, 1)))\n",
    "\n",
    "\n",
    "x = np.random.rand(5)\n",
    "n = Neuron(5)\n",
    "# Вот наш нейрон вычислил некоторое значение\n",
    "print(n.calculate(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Слой\n",
    "\n",
    "Классическая нейронная сеть прямого распространения представляет собой набор слоёв, каждый из которых получает\n",
    "на вход результат вычисления предыдущего слоя\n",
    "\n",
    "Первый слой получает на вход данные для нейронной сети, а выход последнего слоя - это результат работы всей модели\n",
    "\n",
    "Слой можно быол бы реализовать, как класс-контейнер для множества\n",
    "нейронов, но такая никапсуляция излишня, кроме того есть небольшой секрет,\n",
    "который позволит сделать процесс вычисления всего слоя намного быстрее\n",
    "благодаря *numpy*:\n",
    "\n",
    "Слой - одномерный набор нейронов. Значит если мы представим слой, как\n",
    "матрицу, в строках которой нейроны, а в столбцах - их коэффициенты,\n",
    "то весь слой легко представить, как векторную функцию:\n",
    "\n",
    "$$\n",
    "output = \\vec F(\\vec o) \\\\\n",
    "\\vec o =\n",
    "\\begin{pmatrix}\n",
    "w_{11} & w_{12} & \\dots & w_{1p} & b_1\\\\\n",
    "\\ddots & \\ddots & \\ddots & \\ddots & \\ddots \\\\\n",
    "w_{n1} & w_{n2} & \\dots & w_{np} & b_n\n",
    "\\end{pmatrix}\n",
    "*\n",
    "\\begin{pmatrix}\n",
    "x_1 \\\\\n",
    "\\vdots \\\\\n",
    "x_p \\\\ \n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "И действительно, легко заметить, что тогда каждый элемент в выхожном векторе есть $f(\\vec w*\\vec x + b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала реализуем несколько исключений, которые нам понадобятся\n",
    "\n",
    "class LibraryException(Exception):\n",
    "    def __init__(self, msg: str, errs: list = None):\n",
    "        super().__init__(msg)\n",
    "        self.errs = errs\n",
    "        if self.errs:\n",
    "            for e in self.errs:\n",
    "                print(\"\\t\", e)\n",
    "\n",
    "\n",
    "# Для универсальности слоёв и функций активации, сделаем исключение базового класса.\n",
    "# Мы делаем его потому, что я люблю type annotations\n",
    "class DummyClassException(LibraryException):\n",
    "    def __init__(self, classtype: type):\n",
    "        super().__init__(\"The {} class is unusable due to being a base class\".format(classtype.__name__))\n",
    "\n",
    "\n",
    "# Ранее вы заметили, что я проверяю размерности. Данное исключение будем использовать именно для этого\n",
    "class ShapeMismatchException(LibraryException):\n",
    "    def __init__(self, classtype: type, function, need: tuple[int], got: tuple[int]):\n",
    "        super().__init__(\"{} expected {} shape in function {}, got {}\".format(classtype.__name__, need, function.__name__, got))\n",
    "\n",
    "\n",
    "class InternalShapeException(ShapeMismatchException):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовый класс, обеспечивающий вариативность выбора функции при создании слоя\n",
    "class Activation:\n",
    "    \n",
    "    # Вычисление значения от СКАЛЯРА\n",
    "    @staticmethod\n",
    "    def value(x: float) -> float:\n",
    "        raise DummyClassException(Activation)\n",
    "\n",
    "    # Производная в СКАЛЯРНОЙ точке. Она понадобится нам позже.\n",
    "    @staticmethod\n",
    "    def derive(x: float) -> float:\n",
    "        raise DummyClassException(Activation)\n",
    "\n",
    "\n",
    "class SigmoidActivation(Activation):\n",
    "    @staticmethod\n",
    "    def value(x: float) -> float:\n",
    "        ex = exp(x)\n",
    "        return ex/(ex+1)\n",
    "\n",
    "    @staticmethod\n",
    "    def derive(x: float) -> float:\n",
    "        val = SigmoidActivation.value(x)\n",
    "        return val*(1-val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем слой\n",
    "# Функцию активации для простоты будем применять поэлементно\n",
    "# Также реализуем функции активации в виде классов так, чтобы можно было использовать любую из них при создании слоя\n",
    "\n",
    "\n",
    "# Базовый класс для слоя. Он нам тоже понадобится позже\n",
    "class Layer:\n",
    "    def __init__(self, input_size: int, output_size: int, activation_type: type[Activation]):\n",
    "        self.neural_shape = (input_size, output_size)\n",
    "        self.matrix_shape = (output_size, input_size+1)\n",
    "        self.inputs_shape = (input_size,)\n",
    "        self.output_shape = (output_size,)\n",
    "        self.activation = activation_type\n",
    "        self.neurons = None\n",
    "\n",
    "        self.last_inputs = None\n",
    "        self.last_activated = None\n",
    "        self.last_unactivated = None\n",
    "\n",
    "    def calculate(self, inputs: np.array) -> np.array:\n",
    "        raise DummyClassException(Layer)\n",
    "\n",
    "\n",
    "# Так называемый входной слой. Он ничего не делает с получаемыми данными, просто отдает то, что взял\n",
    "# Он нам будет нужен, потому что.\n",
    "class InputLayer(Layer):\n",
    "    def __init__(self, input_size: int):\n",
    "        super().__init__(input_size, input_size, Activation)\n",
    "\n",
    "    def calculate(self, inputs: np.array) -> np.array:\n",
    "        self.last_inputs = np.ndarray.copy(inputs)\n",
    "        self.last_unactivated = np.ndarray.copy(inputs)\n",
    "        self.last_activated = np.ndarray.copy(inputs)\n",
    "\n",
    "        return self.last_activated\n",
    "    \n",
    "\n",
    "# собственно наш полносвязный слой, который представлен матрицей\n",
    "class D1FullLayer(Layer):\n",
    "    def __init__(self, input_size: int, output_size: int, activation_type: type[Activation]):\n",
    "        super().__init__(input_size, output_size, activation_type)\n",
    "\n",
    "        # Вот матрица, о которой я говорил ранее\n",
    "        # output_size - по сути число нейронов\n",
    "        self.neurons = np.random.rand(output_size, input_size+1)\n",
    "\n",
    "    def calculate(self, inputs: np.array) -> np.array:\n",
    "        if self.inputs_shape != inputs.shape:\n",
    "            raise ShapeMismatchException(D1FullLayer, self.calculate, self.inputs_shape, inputs.shape)\n",
    "\n",
    "        self.last_inputs = np.append(inputs, 1)\n",
    "        output = np.dot(self.neurons, self.last_inputs)\n",
    "        if self.output_shape != output.shape:\n",
    "            raise InternalShapeException(D1FullLayer, self.calculate, self.output_shape, output.shape)\n",
    "\n",
    "        self.last_activated = np.array([self.activation.value(x) for x in output])\n",
    "        self.last_unactivated = output\n",
    "\n",
    "        return self.last_activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65433401 0.67623598]\n",
      "\n",
      "[0.7750444  0.80447129 0.62826357 0.58115458 0.79493565 0.59372882\n",
      " 0.67987501 0.60867778 0.68213496 0.61264069]\n",
      "\n",
      "[0.05626878 0.12284134 0.03620381 0.48363657 0.0138788 ]\n",
      "[ True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Проверим, как будет работать наш слой\n",
    "\n",
    "lyr = D1FullLayer(5, 2, SigmoidActivation)\n",
    "print(lyr.calculate(x))\n",
    "print()\n",
    "lyr = D1FullLayer(5, 10, SigmoidActivation)\n",
    "print(lyr.calculate(x))\n",
    "\n",
    "print()\n",
    "# Ну и входной слой для чистоты эксперимента\n",
    "lyr = InputLayer(5)\n",
    "print(lyr.calculate(x))\n",
    "print(lyr.calculate(x) == x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронная сеть\n",
    "\n",
    "Наша сеть, с точки зрения математики, - это просто большая векторная функция. С практической точки зрения это список слоёв, через который прогоняется входной вектор.\n",
    "\n",
    "Реализуем его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork:\n",
    "    def __init__(self, input_size: int):\n",
    "        self.inputs_shape = (input_size,)\n",
    "        self.output_shape = (None,)\n",
    "        # так называемый входной слой добавляем автоматически\n",
    "        self.layers: list[Layer] = [InputLayer(self.inputs_shape[0])]\n",
    "\n",
    "    def add(self, layer_type: type[Layer], output_size: int, activation_type: type[Activation]):\n",
    "        input_size = self.layers[-1].output_shape[0]\n",
    "\n",
    "        self.layers.append(layer_type(input_size=input_size, output_size=output_size, activation_type=activation_type))\n",
    "        self.output_shape = self.layers[-1].output_shape\n",
    "\n",
    "    # Сразу реализуем метод для вычисления множества значений для множества входных векторов\n",
    "    def predict_many(self, x: np.array) -> np.array:\n",
    "        result = []\n",
    "        for example_num, example in enumerate(x):\n",
    "            result.append(self.predict(example))\n",
    "\n",
    "        return np.array(result)\n",
    "\n",
    "    def predict(self, x: np.array) -> np.array:\n",
    "        output = np.ndarray.copy(x)\n",
    "        for layer in self.layers:\n",
    "            output = layer.calculate(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91188291, 0.89595165, 0.92336765, 0.9237787 , 0.93491812,\n",
       "       0.87954396, 0.87940511, 0.78510731, 0.85089038, 0.92262813])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим, что вычислит наша нейронная сеть:\n",
    "\n",
    "net = SimpleNetwork(5)\n",
    "net.add(D1FullLayer, 5, SigmoidActivation)\n",
    "net.add(D1FullLayer, 10, SigmoidActivation)\n",
    "net.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение сети\n",
    "\n",
    "Наша сеть теперь умеет вычислять векторы, получая на вход векторы. Но надо научить ее вычислять векторы, похожие на векторы из обучающих примеров.\n",
    "\n",
    "Как уже упоминалось ранее, по сути нейронаая сеть - это векторная функция $\\vec o(\\vec x)$\n",
    "\n",
    "Для того, чтобы результат работы сети стал похож на то, что мы ей даём, нужно определить меру похожести. Я буду использовать среднюю квадратичную ошибку *MSE*:\n",
    "$$\n",
    "MSE(x) = \\frac{1}{n} \\sum^{n}(real - predicted)^2\n",
    "$$\n",
    "\n",
    "Она-то и покажет нам, насколько мы \"хорошо\" обучили нашу сеть.\n",
    "\n",
    "## Градиентный спуск\n",
    "Теперь становится ясно, что обучение сети - по сути есть изменение ее параметров таким образом, чтобы значение функции ошибки было минимально.\n",
    "\n",
    "На одних и тех же данных наша функция ошибки (назовем ее *L*), очевидно, зависит от параметров нейронной сети, так как зависит (при одних и тех же данных) именно от того, что сеть выдаёт в качестве ответа.\n",
    "\n",
    "Таким образом, имея функцию $L(p_1, \\dots, p_n)$, где $p_k = [[w_11,\\dots,b_1],\\dots,[w_i1,\\dots,b_i]]$ - параметры слоя, мы можем попытаться так подстроить параметры функции *L*, чтобы она становилась меньше и меньше\n",
    "\n",
    "Для этого нам всего лишь надо вычислить градиент этой функции и сместить вектор параметров на антиградиент.\n",
    "\n",
    "Данная функция - сложная, и имеет следующий вид:\n",
    "$$\n",
    "L(\\dots) = MSE(real - \\vec o(\\vec x))\n",
    "$$\n",
    "её частные производные по параметрам равны\n",
    "$$\n",
    "\\frac{\\delta L}{\\delta w} = \\frac{\\delta L}{\\delta \\vec o}*\\frac{\\delta \\vec o}{\\delta w}\n",
    "$$\n",
    "\n",
    "Теперь посчитаем производную функции $\\vec o(\\vec x)$: вспомним, что каждый нейрон - вложенная функция внутри $\\vec o(\\vec x)$, которая как раз и зависит от параметров *w*. Стало быть производная имеет вид\n",
    "\n",
    "$$\n",
    "\\frac{\\delta \\vec o}{\\delta w} = \\frac{\\delta \\vec o}{\\delta n} * \\frac{\\delta \\vec n}{\\delta w}\n",
    "$$\n",
    "\n",
    "Таким образом\n",
    "$$\n",
    "\\frac{\\delta L}{\\delta w} = \\frac{\\delta L}{\\delta \\vec o}*\\frac{\\delta \\vec o}{\\delta n} * \\frac{\\delta \\vec n}{\\delta w}\n",
    "$$\n",
    "\n",
    "Здесь $\\frac{\\delta L}{\\delta \\vec o}$ - всего лишь производная функции ошибки, $\\frac{\\delta \\vec n}{\\delta w}$ - производная функции активации, а вот $\\frac{\\delta \\vec o}{\\delta n}$ - зависит не только от выхода сети, но и от того, сколько слоёв следует после текущего.\n",
    "\n",
    "По сути $\\frac{\\delta \\vec o}{\\delta n}$ - тоже сложная функция с разной глубиной для разных слоев, так что ее вычисление будет реализовываться на уровне сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итак, реализуем недостающие компоненты:\n",
    "class Loss:\n",
    "    @staticmethod\n",
    "    def value(real: np.array, predicted: np.array) -> float:\n",
    "        raise DummyClassException(Loss)\n",
    "\n",
    "    @staticmethod\n",
    "    def derive(real: np.array, predicted: np.array) -> float:\n",
    "        raise DummyClassException(Loss)\n",
    "\n",
    "\n",
    "class MeanSquaredError(Loss):\n",
    "    @staticmethod\n",
    "    def value(real: np.array, predicted: np.array) -> float:\n",
    "        errors = np.array([((real[i] - predicted[i])**2).sum() for i, _ in enumerate(real)])\n",
    "        return errors.mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def derive(real: np.array, predicted: np.array) -> float:\n",
    "        errors = np.array([(-2*(real[i] - predicted[i])).sum() for i, _ in enumerate(real)])\n",
    "        return errors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим в класс сети метод для обучения, который просто вычисляет частные производные по всем параметрам сети\n",
    "# А потом поправляет эти параметры на получившийся антиградиент\n",
    "\n",
    "\n",
    "class Network(SimpleNetwork):\n",
    "    def fit(self, x: np.array, y: np.array, loss_type: type[Loss], lr: float = 0.1):\n",
    "        predicted = self.predict_many(x)\n",
    "        loss = loss_type.value(x, predicted)\n",
    "        dL_dPred = loss_type.derive(y, predicted)\n",
    "\n",
    "        for layer_num, _ in reversed(tuple(enumerate(self.layers))[1:-1]):\n",
    "            next_l = self.layers[layer_num+1]\n",
    "            layer = self.layers[layer_num]\n",
    "\n",
    "            for neuron_num, neuron in enumerate(layer.neurons):\n",
    "                dPred_dH = (next_l.neurons[:, neuron_num]*[next_l.activation.derive(x) for x in next_l.last_unactivated]).mean()\n",
    "\n",
    "                for w_num, _ in enumerate(neuron):\n",
    "                    p1 = layer.last_inputs[w_num]\n",
    "                    p2 = layer.activation.derive(layer.last_unactivated[neuron_num])\n",
    "                    dH1_dW = p1*p2\n",
    "                    layer.neurons[neuron_num][w_num] -= dL_dPred*dPred_dH*dH1_dW*lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc4b0f7a040>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#И проверим, как учится наша сеть, посмотрев, как меняется значение ошибки:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([\n",
    "    [1,2,3],\n",
    "    [2,3,1],\n",
    "    [-1,-2,-3],\n",
    "    [-3,-3,-3],\n",
    "    [1,2,3],\n",
    "    [2,3,1],\n",
    "    [-1,-2,-3],\n",
    "    [-3,-3,-3],\n",
    "    [1,2,3],\n",
    "    [2,3,1],\n",
    "    [-1,-2,-3],\n",
    "    [-1,-3,-3]\n",
    "])\n",
    "y = np.array([\n",
    "    [1],\n",
    "    [1],\n",
    "    [2],\n",
    "    [2],\n",
    "    [1],\n",
    "    [1],\n",
    "    [2],\n",
    "    [2],\n",
    "    [1],\n",
    "    [1],\n",
    "    [2],\n",
    "    [2]\n",
    "])\n",
    "\n",
    "net = Network(3)\n",
    "net.add(D1FullLayer, output_size=3, activation_type=SigmoidActivation)\n",
    "net.add(D1FullLayer, output_size=2, activation_type=SigmoidActivation)\n",
    "net.add(D1FullLayer, output_size=1, activation_type=SigmoidActivation)\n",
    "\n",
    "mse_history = []\n",
    "\n",
    "oldmse = MeanSquaredError.value(y, pred := net.predict_many(x))\n",
    "newmse = oldmse - 1\n",
    "\n",
    "\n",
    "count = 0\n",
    "while count < 1000 and (oldmse-newmse) > 0.000001:\n",
    "    count += 1\n",
    "    oldmse = MeanSquaredError.value(y, pred)\n",
    "    net.fit(x, y, MeanSquaredError, lr=0.1)\n",
    "    newmse = MeanSquaredError.value(y, pred := net.predict_many(x))\n",
    "    mse_history.append(newmse)\n",
    "\n",
    "#%%\n",
    "\n",
    "plt.plot(mse_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# В результате\n",
    "\n",
    "Мы видим, что функция ошибки уменьшается.\n",
    "\n",
    "Наша сеть обучается, и мы прекрасны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
